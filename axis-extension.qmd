---
title: "axis-extension"
format: html
editor: visual

params: 
  eval_models: true
    
execute:
  echo: false
  warning: true
  message: true
  include: false
---

```{r}
#| label: load-packages
library(tidyverse)
library(lme4)
library(lmerTest)
library(buildmer)
library(qwraps2)
library(emmeans)
library(broom.mixed)
library(effectsize)
library(papaja)
library(patchwork)
library(insight)
```

```{r}
#| label: lazyload-cache
if (!params$eval_models){
lazyload_cache_dir('axis-extension_cache/html')}
```

```{r}
#| label: wrangle
anon_data1 <- read_csv('data/anon_data1.csv',
                       col_types = cols(.default = "?", genderResp2.text = col_character()))
# correct the coercion of the genderResp2.text to logical

anon_data2 <- read_csv('data/anon_data2.csv')

# perform necessary data wrangling
wrangle <- function(anon_file, .y) {
  # .y captures the index of the file in the list supplied to iwalk

# extract literacy data
# calculate literacy score (sum of five responses)
literacy <- anon_file %>%
  filter(!is.na(q1_slider.response)) %>%
  rowwise() %>%
  mutate(literacy = sum(c(q1_slider.response, 
                          q2_slider.response, 
                          q3_slider.response, 
                          q4_slider.response, 
                          q5_slider.response))) %>%
  select(participant,
         literacy)

# define education categories 
edu_labels <- set_names(c('No formal qualications',
                          'Secondary education (e.g. GED/GCSE)',
                          'High school diploma/A-levels',
                          'Technical/community college',
                          'Undergraduate degree (BA/BSc/other)',
                          'Graduate degree (MA/MSc/MPhil/other)',
                          'Doctorate degree (PhD/other)',
                          'Don\'t know / not applicable'),
                        seq(8,1,-1))

# define gender categories
gender_labels <- set_names(c("Pnts", 
                             "Another",
                             "NB", 
                             "M", 
                             "F"),
                           1:5)
# extract demographics
# link slider response numbers to gender categories 
# link slider response numbers to education categories
demographics <- anon_file %>%
  filter(!is.na(genderResp1.response)) %>%
  mutate(genderResp1.response = 
           recode(genderResp1.response, !!!gender_labels)) %>%
  mutate(edu_slider.response =
           recode(edu_slider.response, !!!edu_labels)) %>%
  select(participant,
         ageResp.text,
         genderResp1.response,
         edu_slider.response)

# extract duration data (in seconds)
durations <- anon_file %>%
  filter(!is.na(total_duration)) %>%
  select(participant, total_duration)
  
# select relevant columns
# select only experimental items
# add literacy and demographic data
# change data types where appropriate
# output this file with suffix 'tidy'
anon_file %>% 
  filter(item_type == "E") %>%
  select(matches(c("participant",
                   "item_no",
                   "item_type",
                   "cond",
                   "axis",
                   "denominator",
                   "slider.response",
                   "mag_slider.response",
                   "con_slider.response",
                   "seed_no"))) %>% 
    inner_join(literacy, by = "participant") %>%
    inner_join(demographics, by = "participant") %>%
    inner_join(durations, by = "participant") %>%
    mutate(total_duration = total_duration / 60) %>%
    mutate(across(matches(c("cond", "axis")), 
                  ~ case_match(.x,
                               "full" ~ "extend",
                               "trunc" ~ "default"))) %>%
    mutate(across(matches(c("axis", "denominator", "cond")), as_factor)) %>%
    mutate(across(c("participant", "item_no"), as.character)) %>%
    assign(paste0("e", .y),
           value = ., envir = .GlobalEnv)
}

iwalk(list(anon_data1, anon_data2), wrangle)


# set sum contrasts
contrasts(e2$axis) <- contr.sum(2)
contrasts(e2$denominator) <- contr.sum(2)
```

```{r}
#| label: anova-results-function
# this function takes two nested models, runs an anova, and the outputs the Likelihood Ratio Statistic, degrees of freedom, and p value to the global environment
anova_results <- function(test_model, full_model) {
  
  # first argument 
  test_model_name <- deparse(substitute(test_model))
  full_model_name <- deparse(substitute(full_model))

  if (class(test_model) == "buildmer") test_model <- test_model@model
  if (class(full_model) == "buildmer") full_model <- full_model@model
  
  anova_output <- anova(test_model, full_model)
  
  assign(paste0(test_model_name, ".Chi"),
         anova_output$Chisq[2],
         envir = .GlobalEnv)
  assign(paste0(test_model_name, ".Df"),
         anova_output$Df[2],
         envir = .GlobalEnv)
  assign(paste0(test_model_name, ".p"),
         anova_output$`Pr(>Chisq)`[2],
         envir = .GlobalEnv)
  
  es <- eta_squared(anova(full_model), partial = TRUE) 
  
  es %>% pull(Parameter) %>%
    map(function(x) assign(paste0(model_name, 
                                  ".eta.", 
                                  str_replace(x, ":", "_")),
                           es %>%
                             filter(Parameter == x) %>% 
                             pull(Eta2_partial),
                           envir = .GlobalEnv))
}
```

```{r}
#| label: summary-extract-function

# this function extracts test statistics and p values from model summaries
summary_extract <- function(model) {
  
  model_name <- deparse(substitute(model))
  
  if (class(model) == "buildmer") model <- model@model
  
  es <- eta_squared(anova(model), partial = TRUE) 

  model %>% 
    anova() %>%
    as_tibble(rownames = "term", 
              .name_repair = make.names) %>%
    rename("p" = "Pr..F.") %>%
    inner_join(es, by = join_by("term" == "Parameter")) %>%
    mutate(term = str_replace(term, ":", "_")) %>%
    group_split(term) %>%
    map(~ {
      vals <- as.list(.x)
      names(vals) <- paste0(model_name, 
                            "_", 
                            .x$term, 
                            "_", 
                            names(vals))
      list2env(vals, envir = globalenv())
    })
  
}
```

```{r}
#| label: get-contrasts-function

get_contrasts <- function(contrast_df, condition) {

  df_name <- deparse(substitute(contrast_df))

  contrast_df %>% 
    contrast("consec", 
             simple = "each", 
             combine = TRUE, 
             adjust = "sidak") %>%
    as_tibble() %>% 
    filter(!!sym(condition) != ".") %>%
    group_split(!!sym(condition)) %>%
    map(~ {
      vals <- as.list(.x)
      names(vals) <- paste0(df_name, 
                            "_",
                            pull(., {{condition}}),
                            "_", 
                            names(vals))
      list2env(vals, envir = globalenv())
    })
  
}
```

```{r}
#| label: random-str-function

# this function creates a table which displays the random effects structure (intercepts and slopes) for a given model
random_str <- function(model) {
  model <- model@model
  terms <- model %>% find_random %>% unlist() %>% unname()
  mylist <- model %>% formula %>% findbars() %>% as.character()
  slopes <- lapply(mylist, str_extract, "(?<=\\+ )(.*)(?= \\| )") %>% 
    unlist()
  tibble(terms, slopes)
}
```

```{r}
#| label: get-anomalies-function

# returns the proportion of datasets which needed to re-generated for the highest data point to exceed the highest gridline

get_anomalies <- function(dataset){
  dataset %>%
  pull(seed_no) %>% # extract column with seed numbers
  unique() %>% # get unique values
  na.omit() %>% # omit NAs
  sort() %>% # ascending order (since they were generated in order)
  diff() %>% # calculate difference between each pair of values
  # the while loop was entered on every trial including the first
  # the first seed value in both experiments is 2
  # this indicates that a new seed number was not selected for the first chart
  #c(1, .) %>% # therefore we prepend a 1 to indicate this
  `>`(1) %>% # count the number of cases where a new seed number was selected
  mean()*100 # calculate the proportion of TRUE cases as a %
}
```

```{r}
#| label: print-es-function
# for dealing with effect sizes less than .001
print_es <- function(x) {ifelse(x<.001, "< 0.001", paste("=", printnum(x)))}
```

```{r}
#| label: gender-proportions
gender_e1 <- e1 %>%
    distinct(participant, .keep_all = TRUE) %>% 
    group_by(genderResp1.response) %>% summarise(cnt = n()) %>%
    reframe(freq = cnt / sum(cnt) *100, 
            gender = unique(genderResp1.response)) %>%
  pivot_wider(names_from = gender, values_from = freq)

gender_e2 <- e2 %>%
    distinct(participant, .keep_all = TRUE) %>% 
    group_by(genderResp1.response) %>% summarise(cnt = n()) %>%
    reframe(freq = cnt / sum(cnt) *100, 
            gender = unique(genderResp1.response)) %>%
  pivot_wider(names_from = gender, values_from = freq)
```

{{< include text_body/introduction.md >}}

Datasets for `r printnum(get_anomalies(e1), digits = 0)`% of items were recreated to ensure that the highest value exceeded the highest gridline when the default axis setting was used.

Datasets for `r printnum(get_anomalies(e2), digits = 0)`% of items were recreated to ensure that the highest value exceeded the highest gridline when the default axis setting was used.

# Experiment 1

Experiment 1 investigates the influence of y-axis upper bounds on interpretations of plotted values' magnitude. Participants viewed bar charts with y-axes which either terminated just above the bars, or extended to a denominator value well above the bars. Thus, the same data is displayed with and without its surrounding context. Comparing participants' interpretations captures the influence of y-axis limits on magnitude judgements.

## Pre-Registration

We predicted that bar charts with truncated axes would elicit greater magnitude ratings than bar charts with extended axes. Pre-registration is available at https://osf.io/e9j43.

## Method

### Materials

We developed 40 scenarios relating to fictitious surveys and experiments. Each scenario described a study evaluating a specific outcome in each of five categories (e.g., the number of employees achieving performance targets, in five finance companies). The denominator (e.g., total number of employees) was identical for each category. Participants were asked to make judgements about overall magnitude (e.g., How well did the employees perform?), responding on a visual analogue scale with anchors at the extremes (e.g., 'very poorly', 'very well').

We generated bar charts using ggplot2 in R (version 4.1.2), using tidyverse version 1.3.1 and ggh4x version 0.2.1. Both versions of each chart displayed the same five values, but employed different y-axis upper bounds. For extended charts, the denominator from the text description (400, 500, or 600) was used as the y-axis upper bound. The denominators were also used in the generation of the datasets, which employed a normal distribution with a mean equal to 20% or 40% of a given denominator value, and a standard deviation equal to 1% of a given denominator value.

In truncated charts, the y-axis upper bound was dictated by ggplot2's default axis settings. These settings automatically identify a set of convenient breaks for each dataset, then slightly extend the plot area, adding 5% of the axis range to the upper axis limit. In both conditions, contrary to the default settings, a smaller expansion factor of 1% was applied to the lower axis limit, eliminating visible space below the 0 baseline.

The default settings tended to produce charts where the highest axis break fell below the tallest bar. For the purposes of consistency, when the opposite situation occured, we automatically generated an alternative dataset to ensure the highest axis break appeared below the tallest bar. This dataset was used in both conditions. In our stimuli set, x alternative datasets were generated in this way.

In experimental trials, plotted values consisted of relatively small proportions of the denominator value specified in the accompanying text (roughly 20% or 40%). To introduce variety and encourage attention, eight filler trials showed plotted values which were around 90% of the corresponding denominator value. The denominators were selected so that numerical labels on the y-axis roughly resembled either extended or truncated experimental trials.

We included six attention check trials to assess participants' engagement with the task. These trials were similar to experimental and filler trials, comprising of text, a bar chart, question and visual analogue scale. However, participants were instructed to ignore the bar chart and provide a specified response on the visual analogue scale.

### Procedure

PsychoPy version 2022.1.4. Participants were instructed to carry out the experiment using a laptop or desktop computer (not a mobile phone or tablet). After providing informed consent, participants completed a demographic questionnaire and Garcia-Retamero et al.'s (2016) subjective data visualisation literacy measure. Participants were asked to image they were a researcher tasked with determining the outcome of experiments and surveys. They were instructed to make an overall assessment of all data presented in the graph after studying the text, graph, and question. Items were presented in a random order. There was a total of 46 trials.

Participants were permitted to move the response marker as many times as they liked before proceeding to the next trial, but could not return to previous trials. Finally, they were informed that all data presented was fictitious and were given the option to provide comments on the experiment and describe any strategies used. Average completion time was `r printnum(e1 %>% pull(total_duration) %>% mean(), digits = 1)` minutes.

### Design

We employed a within-participants design: participants viewed 16 different charts in each of the two conditions (32 experimental trials total). The correspondence between scenarios and conditions was counterbalanced using two lists. However, all participants saw the same versions of the eight filler items and six attention check items.

### Participants

Participants were recruited using Prolific.co. The experiment was advertised to fluent English speakers, who had normal-or-corrected to normal vision, who had previously participated in at least 100 studies on the site.

Data were returned by 157 participants. Per pre-registered exclusion criteria, seven participants' submissions were rejected because they answered more than one of six attention check questions incorrectly.

The final sample consisted of 150 participants (`r printnum(gender_e1$M)`% male, `r printnum(gender_e1$F)`% female, `r printnum(gender_e1$NB)`% non-binary). Mean age was `r printnum(e1 %>% pull(ageResp.text) %>% mean())` (*SD* = `r printnum(e1 %>% pull(ageResp.text) %>% sd())`). The mean data visualisation literacy score was `r printnum(e1 %>% pull(literacy) %>% mean())` (*SD* = `r printnum(e1 %>% pull(literacy) %>% sd())`), out of a maximum of 30.

Participants with accepted submissions received £3.50.

This experiment was approved by the University of Manchester's Division of Neuroscience and Experimental Psychology Ethics Committee (ethics code: 2022-11115-24245).

## Analysis

### Magnitude Ratings

```{r}
#| label: fig-e1-mag
#| include: true
e1 %>%
  ggplot(aes(x = slider.response, y = cond)) +
  geom_jitter(width = 0,
              height = 0.2,
              alpha = 0.1) +
  scale_y_discrete(breaks = c("extend", "default"),
                   labels = c("Extended", "Default")) + 
  labs(title = 'Experiment 1',
      y = NULL,
       x = NULL) + 
  scale_x_continuous(labels = c('Very low\nmagnitude', 'Very high\nmagnitude'),
    breaks = c(1,2),
    minor_breaks = c()) + 
  theme_minimal(base_size = 16)
```

@fig-e1-mag shows the raw data.

```{r}
#| label: e1-mag
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e1_mag <- buildmer(slider.response ~ cond +
                     (1 + cond | participant) + 
                     (1 + cond | item_no),
                   data = e1)
```

```{r}
summary_extract(e1_mag)
```

Participants awarded higher ratings to charts with default axes, compared to charts with extended axes: F(`r printnum(e1_mag_cond_NumDF)`, `r printnum(e1_mag_cond_DenDF)`) = `r printnum(e1_mag_cond_F.value)`, p `r printp(e1_mag_cond_p, add_equals = T)`, partial $\eta^2$ = `r printnum(e1_mag_cond_Eta2_partial)`.

```{r}
#| include: false
random_str(e1_mag)
```

This model employed a maximal random effects structure, capturing the baseline responses (intercepts) and differences between the two axis settings (slopes) separately for each individual participant and each individual item.

### Magnitude Ratings and Data Visualisation Literacy

```{r}
#| label: e1-lit
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e1_mag_l <- lmer(add.terms(formula(e1_mag),
"literacy"),
              data = e1)
```

```{r}
summary_extract(e1_mag_l)
```

Accounting for differences in data visualisation literacy did not change the significant effect of axis upper bound F(`r printnum(e1_mag_l_cond_NumDF)`, `r printnum(e1_mag_l_cond_DenDF)`) = `r printnum(e1_mag_l_cond_F.value)`, p `r printp(e1_mag_l_cond_p, add_equals = T)`, partial $\eta^2$ = `r printnum(e1_mag_l_cond_Eta2_partial)`.

# Experiment 2

## Pre-Registration

We predicted an interaction between axis limits and denominator presence. Pre-registration is available at https://osf.io/hx9y4.

# Method

### Materials

We generated bar charts using ggplot2 in R (version 4.2.1), using tidyverse (version 1.3.2) and ggh4x (version 0.2.3). The same scenarios were used as in E1 and bar charts were generated using the same method. We expanded the range of denominators, employing the following values: Consequently, the values plotted in the charts and on the axes, differed from E1.

Differences in filler trials - 32 not 8

We added the word 'surveyed' or 'assessed' to seven accompanying sentences in items from E1, that were unclear in the absence of a denominator.

### Procedure

The procedure was identical to Experiment 1, except for the addition of a confidence rating...

Average completion time was `r printnum(e2 %>% pull(total_duration) %>% mean(), digits = 1)` minutes.

### Design

We employed a within-participants 2x2 Latin-squared design with two factors: axis upper bound (default vs. extended) and denominator presence (present vs. absent). Participants viewed 8 different charts for each combination of conditions (32 experimental trials total). The correspondence between scenarios and conditions was counterbalanced using four lists. However, all participants saw the same versions of the 32 filler items and six attention check items.

### Participants

Participants were recruited using Prolific.co, using the same inclusion criteria as Experiment 1. Individuals who completed E1 were prevented from participating.

Data were returned by xxx participants. Per pre-registered exclusion criteria, xxx participants' submissions were rejected because they answered more than one of six attention check questions incorrectly.

The final sample consisted of 150 participants (`r printnum(gender_e2$M)`% male, `r printnum(gender_e2$F)`% female, `r printnum(gender_e2$NB)`% non-binary, `r printnum(gender_e2$Another)`% other, `r printnum(gender_e2$Pnts)`% prefer not say). Mean age was `r printnum(e2 %>% pull(ageResp.text) %>% mean())` (*SD* = `r printnum(e2 %>% pull(ageResp.text) %>% sd())`). The mean data visualisation literacy score was `r printnum(e2 %>% pull(literacy) %>% mean())` (*SD* = `r printnum(e2 %>% pull(literacy) %>% sd())`), out of a maximum of 30.

Participants with accepted submissions received £5.00.

This experiment was approved by the University of Manchester's Division of Neuroscience and Experimental Psychology Ethics Committee (ethics code: 2023-11115-28428).

## Analysis

### Magnitude Ratings

```{r}
#| label: fig-e2-mag
#| include: true

denom_labs <- c("Denominator Present in Text", 
                 "Denominator Absent from Text")
names(denom_labs) <- c("pres", "abs")

e2 %>%
  ggplot(aes(x = mag_slider.response, y = axis)) +
  geom_jitter(width = 0,
              height = 0.2,
              alpha = 0.1) +
  scale_y_discrete(limits = c("extend", "default"),
                   labels = c("Extended", "Default")) + 
  labs(title = 'Experiment 2',
      y = NULL,
       x = NULL) + 
  scale_x_continuous(labels = c('Very low\nmagnitude', 'Very high\nmagnitude'),
    breaks = c(1,2),
    minor_breaks = c()) + 
  facet_wrap(vars(denominator), ncol = 1, labeller = labeller(denominator = denom_labs)) +
  theme_minimal(base_size = 16)
```

@fig-e2-mag shows the raw data.

```{r}
#| label: e2-mag
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_mag <- buildmer(mag_slider.response ~ axis*denominator +
                     (1 + axis*denominator | participant) + 
                     (1 + axis*denominator | item_no),
                   data = e2)
```

```{r}
summary_extract(e2_mag)
```

a 2 (axis) x 2 (denominator) factorial ANOVA

Charts with default axes elicited higher ratings than chart with extended axes (F(`r printnum(e2_mag_axis_NumDF)`, `r printnum(e2_mag_axis_DenDF)`) = `r printnum(e2_mag_axis_F.value)`, p `r printp(e2_mag_axis_p, add_equals = T)`, partial $\eta^2$ = `r printnum(e2_mag_axis_Eta2_partial)`) and charts not accompanied by a denominator in text elicited higher ratings than those accompanied by a denominator (F(`r printnum(e2_mag_denominator_NumDF)`, `r printnum(e2_mag_denominator_DenDF)`) = `r printnum(e2_mag_denominator_F.value)`, p `r printp(e2_mag_denominator_p, add_equals = T)`, partial $\eta^2$ = `r printnum(e2_mag_denominator_Eta2_partial)`).

Crucially, there was also a significant interaction between axis upper bound and denominator presence: F(`r printnum(e2_mag_axis_denominator_NumDF)`, `r printnum(e2_mag_axis_denominator_DenDF)`) = `r printnum(e2_mag_axis_denominator_F.value)`, p `r printp(e2_mag_axis_denominator_p, add_equals = T)`, partial $\eta^2$ = `r printnum(e2_mag_axis_denominator_Eta2_partial)`.

```{r}
#| label: e2-mag-contrasts

e2_mag_emm <- emmeans(e2_mag@model, pairwise ~ axis * denominator, adjust = 'sidak') 
  
get_contrasts(e2_mag_emm, condition = "denominator")
```

Pairwise comparisons reveal that charts with extended and default axes were rated differently when the denominator was present, replicating the effect from E1 (z = `r printnum(e2_mag_emm_pres_z.ratio)`, p `r printp(e2_mag_emm_pres_p.value, add_equals = TRUE)`), and also when the denominator was absent (z = `r printnum(e2_mag_emm_abs_z.ratio)`, p `r printp(e2_mag_emm_abs_p.value)`). Therefore, the interaction indicates that the degree of difference in magnitude ratings was affected by whether the denominator was present or absent.

The presence of a denominator decreased magnitude ratings for default charts, as expected: F... However, it also decreased magnitude ratings for extended charts: .

```{r}
#| include: false
random_str(e2_mag)
```

This model employed by-participant and by-item random effects. For each participant, there were random intercepts, plus random slopes for axis settings and denominator presence. For each item, there were random intercepts, plus random slopes for denominator presence.

```{r}
#| label: fig-e2-mag-int
#| include: true
#| message: false

my_palette <- unname(palette.colors(palette = "Okabe-Ito")[2:3])

emmip(e2_mag@model, denominator ~ axis, CIs = T, 
      dotarg = list(shape = "circle", size = 2), 
      linearg = list(linetype = "solid", lwd = 1.5),
      CIarg = list(lwd = 3, alpha = 0.5)) +
  scale_color_manual(limits = c('abs', 'pres'), 
                   labels = c('Absent from text', 'Present in text'),
                   values = my_palette) +
  scale_x_discrete(limits = c('extend', 'default'), 
                       labels = c('Extended', 'Default')) +
  scale_y_continuous(limits = c(1,2), 
                     breaks = c(1,2), 
                     minor_breaks = seq(1,2,0.2),
                     labels = c('Very low\nmagnitude', 
                                'Very high\nmagnitude')) + 
  labs(x = "Axis Upper Bound",
       y = "Magnitude Rating",
       color = "Denominator in Text",
       title = "Experiment 2 - Magnitude Ratings",
       subtitle =  "Estimated Marginal Means") + 
  theme_minimal(base_size = 16)
```

@fig-e2-mag-int shows the interaction.

### Magnitude Ratings and Data Visualisation Literacy

```{r}
#| label: e2-lit
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_mag_l <- lmer(add.terms(formula(e2_mag),
"literacy"),
              data = e2)
```

### Confidence Ratings

```{r}
#| label: fig-e2-con
#| include: true

denom_labs <- c("Denominator Present in Text", 
                 "Denominator Absent from Text")
names(denom_labs) <- c("pres", "abs")

e2 %>%
  ggplot(aes(x = con_slider.response, y = axis)) +
  geom_jitter(width = 0,
              height = 0.2,
              alpha = 0.1) +
  scale_y_discrete(breaks = c("extend", "default"),
                   labels = c("Extended", "Default")) + 
  labs(title = 'Experiment 2',
      y = NULL,
       x = NULL) + 
  scale_x_continuous(labels = c('Not very\nconfident', 'Very\nconfident'),
    breaks = c(1,2),
    minor_breaks = c()) + 
  facet_wrap(vars(denominator), ncol = 1, labeller = labeller(denominator = denom_labs)) +
  theme_minimal(base_size = 16)  
```

@fig-e2-con shows the raw data.

```{r}
#| label: e2-con
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_con <- buildmer(con_slider.response ~ axis*denominator +
                     (1 + axis*denominator | participant) + 
                     (1 + axis*denominator | item_no),
                   data = e2)
```

```{r}
#| label: e2-con-anova

e2_con_summ <- anova(e2_con) %>% as_tibble(rownames = "FixEf", .name_repair = make.names) %>%
  rename("Pr" = "Pr..F.")
```

```{r}
#| label: e2-con-contrasts

e2_con_emm <- emmeans(e2_con@model, pairwise ~ axis * denominator, adjust = 'sidak') 
  
get_contrasts(e2_con_emm, condition = "denominator")
```

```{r}
#| label: fig-e2-con-int
#| include: true
#| message: false
#| fig-cap: with 95% confidence intervals

my_palette <- unname(palette.colors(palette = "Okabe-Ito")[2:3])

emmip(e2_con@model, denominator ~ axis, 
      CIs = T, 
      dotarg = list(shape = "circle", size = 2), 
      linearg = list(linetype = "solid", lwd = 1.5),
      CIarg = list(lwd = 3, alpha = 0.5)) +
  scale_color_manual(limits = c('abs', 'pres'), 
                   labels = c('Absent from text', 'Present in text'),
                   values = my_palette,
                   guide = guide_legend(reverse=T)) +
  scale_x_discrete(limits = c('extend', 'default'), 
                       labels = c('Extended', 'Default')) +
  scale_y_continuous(limits = c(1,2), 
                     breaks = c(1,2), 
                     minor_breaks = seq(1,2,0.2),
                     labels = c('Not very\nconfident', 
                                'Very\nconfident')) + 
  labs(x = "Axis Upper Bound",
       y = "Magnitude Rating",
       color = "Denominator in Text",
       title = "Experiment 2 - Confidence Ratings",
       subtitle =  "Estimated Marginal Means") + 
  theme_minimal(base_size = 16)
```

@fig-e2-con-int shows the interaction.

### Confidence Ratings and Data Visualisation Literacy

```{r}
#| label: e2-con-lit
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_con_l <- lmer(add.terms(formula(e2_con),
"literacy"),
              data = e2)
```
